from langsmith import traceable
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Dict
import uvicorn
import os
from langchain_together import Together
from dotenv import load_dotenv
import re

# Load bi·∫øn m√¥i tr∆∞·ªùng
load_dotenv()

# Kh·ªüi t·∫°o LLM
llm = Together(
    model="deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free",
    temperature=0.0,
    max_tokens=1024,
    together_api_key=os.getenv("TOGETHER_API_KEY")
)

# Kh·ªüi t·∫°o app FastAPI
app = FastAPI()

# C·∫•u h√¨nh CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Khai b√°o schema nh·∫≠n t·ª´ frontend
class DynamicData(BaseModel):
    system_prompt: str  # üëà th√™m system prompt
    prompt: str          # n·ªôi dung prompt ch√≠nh
    data: Dict[str, str] # d·ªØ li·ªáu ng∆∞·ªùi d√πng nh·∫≠p

# Endpoint t·∫°o h·ªì s∆°
@app.post("/generate-document")
@traceable
def generate_doc(request_data: DynamicData):
    # Gh√©p prompt
    combined_prompt = f"{request_data.system_prompt.strip()}\n\n{request_data.prompt.strip()}"

    # Thay th·∫ø bi·∫øn {key} trong prompt
    for key, value in request_data.data.items():
        combined_prompt = combined_prompt.replace(f"{{{key}}}", value)

    # G·ªçi LLM sinh n·ªôi dung
    result = llm.invoke(combined_prompt)
    if hasattr(result, "content"):
        result = result.content

    # X·ª≠ l√Ω lo·∫°i b·ªè tag <think> n·∫øu c√≥
    result = re.sub(r"<think>.*?</think>", "", result, flags=re.DOTALL)
    result = re.sub(r"<?think>", "", result)
    result = re.sub(r"</?think>", "", result)
     # ‚úÖ L·∫•y t·ª´ "Th√¥ng tin:" tr·ªü ƒëi
    match = re.search(r"Th√¥ng tin:(.|\n)*", result)
    if match:
        result = match.group(0)
    else:
        result = result.strip()

    return {"document": result}

# Kh·ªüi ƒë·ªông server
if __name__ == "__main__":
    uvicorn.run(app, host="127.0.0.1", port=8000)
